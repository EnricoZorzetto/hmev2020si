---
title: "Hierarchical Bayesian modelling of hydrological extremes"
author: 
  - Enrico Zorzetto^[Division of Earth and Ocean Sciences, Duke University, Durham, NC \textcolor{blue}{enrico.zorzetto@duke.edu}]
  - Antonio Canale^[Department of Statistical Sciences, University of Padova, Padova, Italy]
  - Marco Marani^[Department of Civil, Environmental and Architectural Engineering, University of Padova, Padova, Italy]
# author: "Enrico Zorzetto, Antonio Canale, and Marco Marani"
date: "5/6/2020"
output: beamer_presentation
bibliography: hbev_bib.bib
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


## Scope of the work

- We present an extension of the Metastatistical Extreme Value Distribution [@marani2015metastatistical; @zorzetto2016emergence] aimed at 
quantifying estimation uncertainty in extreme value modelling of hydrological time series.

- The interannual variability of hydrological variables
is described through a '\emph{slow}' latent variable level varying with yearly time scale.

- Elicitation of informative prior distributions allows for the inclusion of physical information aimed at reducing estimation uncertainty.

- Here we present an application to daily rainfall extremes over the continental United States, and report a benchmark comparison to other extreme value models.


## Model Structure


&nbsp;

::: columns

:::: column

Observed quantities:

- $x_{ij}$ = $i-th$ event magnitude in block $j$
- $n_j$ = number of events in block $j$

We specify parametric models for event magnitudes $\theta_j$ and occurrence $\lambda$.
Magnitudes parameters $\theta_j$ are in turn generated by a latent yearly parametric model $\eta$
::::

:::: column 

Schematic structure of the hierarchical model. Observed quantities are grey-shaded, parameters in white:
```{r structure, echo=FALSE, fig.lp = "fig:", fig.cap="", out.width = '100%'}
knitr::include_graphics("../output/outplot/structure.png")
```

::::
:::

<!-- &nbsp; -->

We model the non exceedance probability of annual maxima $y$ as



\begin{equation*}
P(Y \le y \mid \lambda, \eta) = \sum_{n = 0}^{N_t} \int_{\Theta} F(y ; \theta)^{n} g(\theta; \eta) p(n; \lambda)d\theta.
\label{eq:zeta}
\end{equation*}

<!-- &nbsp; -->

## Prior elicitation

We need to specify prior distributions for the model of event magnitudes and frequency of occurrence:

- Weakly informative prior for the occurrences' model ($n_j$)

- Informative priors for the magnitudes ($x_{ij}$) model. These can be based on:
    * Shape parameter priors based on the analysis by Wilson and Toumi [-@wilson2005fundamental], e.g., prior belief of sub-exponential tails.
    * Scale parameter priors can be based on information on climatic variability, or empirical, based on observations of the local rainfall characteristic intensity.
    
## Posterior computation
    
- Analytical expression for the posterior distribution is not available, so we use an approximation obtained by a Markov Chain Monte Carlo (MCMC) approach. Based on the posterior distribution of the model's parameters, functionals of interest such as the cumulative probability $\zeta (y)$ of a value $y$ can be approximated by the expectation over $B$ MCMC posterior draws:


\begin{equation}
\hat{\zeta}_{MC}(y) =\frac{1}{B} \sum_{b=1}^{B} \hat{\zeta}^{(b)}(y).
\label{eq:zetaMC_s}
\end{equation}

- In the case of time series with significant correlation, we decluster the time series following the procedure proposed by [@marra2018metastatistical].


## Example of application to the New York Central Park time series


```{r nycp, echo=FALSE, fig.lp = "fig:", fig.cap="", out.width = '70%'}
knitr::include_graphics("../output/outplot/nycp_time_series.png")
```
Data source: NOAA USHCN Station ID USW00094728 [@menne2012global]

## Posterior predictive checks

```{r ppc, echo=FALSE, fig.lp = "fig:", fig.cap="", out.width = '90%'}
knitr::include_graphics("../output/outplot/nycp_ppdf_pdf.png")
```

Posterior predictive checks for annual maxima (a), yearly number of events (b), and all daily values (c). Observed densities are in black, and MCMC replicates in blue.

## Estimation of quantiles from small samples

```{r plotqtr, echo=FALSE, fig.lp = "fig:", fig.cap="", out.width = '80%'}
knitr::include_graphics("../output/outplot/nycp_50_years.png")
```
Example of quantile estimates from the model described here (HMEV) and comparison
with other extreme value models for a sample time series (POT, GEV). Estimates are compared 
to in-sample (triangles) and out-of-sample (circles) data points

## Mapping return levels and relative uncertainty

```{r qmap, echo=FALSE, fig.lp = "fig:", fig.cap="", out.width = '70%'}
knitr::include_graphics("../output/outplot/quantiles_maps_kfold_479_0_dec.png")
```

50-years return level and relative uncertainty. The color indicates the magnitude of the expected 50-years daily rainfall, while the marker size is proportional to the relative width of the posterior $90\%$ probability intervals.

## Measuring predictive accuracy

To measure the predictive accuracy of the model (with posterior predictive distribution approximated by $B$ posterior draws) for $n$ annual maxima values $y_i, \dots y_n$ we use:

<!-- is expressed by the \emph{expected log pointwise predictive density}, or \emph{elpd}, which reads \citep{gelman2013bayesian} -->

<!-- \begin{equation} -->
<!-- elpd = \sum_{i=1}^{n} \int p_t \left( \tilde{y_i} \right) \log{p \left( \tilde{y_i} \mid y \right)} d \tilde{y_i} -->
<!-- \label{eq:elpd} -->
<!-- \end{equation} -->
<!-- where the $p_t \left( \tilde{y_i} \right)$ are the unknown probability densities of the $\tilde{y_i}$ under the true model. A more accessible quantity is the  -->


1. The \emph{log pointwise predictive density}, or \emph{lppd}:
<!-- \begin{equation} -->
<!-- lppd = -\frac{1}{n}\sum_{i=1}^{n}  \int p( \tilde{y_i} \mid \theta) p(\theta \mid y) d \theta -->
<!-- \end{equation} -->
<!-- which can be directly estimated from $S$ draws from the posterior simulation as -->
\begin{equation}
    lppd = -\frac{1}{n}\sum_{i = 1}^{n} log \left( \frac{1}{B}\sum_{b = 1}^{B} p(y_i \lvert
    {\theta}^{(b)})\right)
\end{equation}

<!-- Given a sample of annual maxima $y_i,  \quad, i = 1, N$, we compute  -->
2. The \emph{log posterior marginal likelihood}, or \emph{lpml} [@gelfand1994bayesian]:

\begin{equation}
    lpml = -\frac{1}{n}\sum_{i = 1}^{n} \log{\left( \left[ \frac{1}{B} \sum_{b = 1}^{B} \frac{1}{p\left( y_i \mid
    \mathbf{\theta}^{\left(b\right)}\right)}\right]^{-1} \right)}
\end{equation}

<!-- \begin{equation} -->
<!--     lpml = -\frac{1}{n}\sum_{i = 1}^{n} \log{\left(  \left\{\int \frac{1}{p\left( y_i \mid -->
<!--         \mathbf{\theta}\right)} p \left( \mathbf{\theta} \mid -->
<!--     \mathbf{y_{-1}} \right) d \mathbf{\theta} \right\}^{-1} \right)} -->
<!-- \end{equation} -->

<!-- where we add the factor $-1/m$ to reduce its variation with sample size. -->
<!-- Here $CPO_i$ is the \emph{Conditional Predictive Ordinate} statistics introduced by -->
<!-- [@gelfand1992model] and [@gelfand1994bayesian], which estimates the -->
<!-- probability of observing a value $y_i$ given that $\mathbf{y}_{-i}$ has been -->
<!-- observed. $CPO_i$ can be obtained as follows: -->

<!-- \begin{equation} -->
<!--     CPO_i =  \left\{\int \frac{1}{p\left( y_i \mid -->
<!--         \mathbf{\theta}\right)} p \left( \mathbf{\theta} \mid -->
<!--     \mathbf{y_{-1}} \right) d \mathbf{\theta} \right\}^{-1} -->
<!-- \end{equation} -->

<!-- The CPO can be computed as the geometric mean of the likelihood of the data -->
<!-- (annual maxima) given the model. Sampling from the posterior, one can compute$CPO_i$ as follows:  -->

<!-- \begin{equation} -->
<!--     CPO_i = \left[ \frac{1}{B} \sum_{b = 1}^{B} \frac{1}{p\left( y_i \mid -->
<!--     \mathbf{\theta}^{\left(b\right)}\right)}\right]^{-1} -->
<!-- \end{equation} -->

Here we use the difference between \emph{lpml} and \emph{lppd} to quantify a model's tendency to overfit a sample of annual maxima. Both measures are evaluated numerically from $B = 4000$ MCMC posterior draws.

## Effective number of parameters

```{r effnumpar, echo=FALSE, fig.lp = "fig:", fig.cap="", out.width = '90%'}
knitr::include_graphics("../output/outplot/eff_num_par_kfold_479_0_dec.png")
```

Effective number of parameters of different models, based on the difference between \emph{lpml} and \emph{lppd}. Including more data in the analysis tends to reduce overfit to the annual maxima.

## Testing model performance

```{r performance, echo=FALSE, fig.lp = "fig:", fig.cap="", out.width = '70%'}
knitr::include_graphics("../output/outplot/bestm_kfold_479_0_dec_fraction_stations.png")
```

Benchmark with other extreme value models, including log posterior predictive density (lppd) and a fractional square error (fse) computed for return times $T_r> 2$ years. 

## Contributions


- We introduce a hierarchical model for describing extremes of environmental time series.

- Building on the Metastatistical Extreme Value Distribution, this approach now allows to 
quantify estimation uncertainty through a Bayesian approach.

- This method can reduce estimation uncertainty for small sample sizes, as evaluated using out-of-sample data for independent validation. 

- Our analysis underlines the importance of out-of-sample validation for extreme value models. 
When long time series are not available for independent cross validation, in-sample techniques such as \emph{lpml} can help inform model selection.

## References {.allowframebreaks}

